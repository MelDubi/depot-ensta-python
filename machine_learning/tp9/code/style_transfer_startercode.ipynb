{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center> **Deep style transfer** </center>\n",
    "\n",
    "## <center> Machine Learning Programming Exercise 9</center>\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "DRJ9fZnITFFU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "| <font size=6,font color='red'>Monôme / binôme</font> | <font size=6,font color='red'>Nom</font> | <font size=6,font color='red'>Prénom</font> |\n",
    "|:-------------: |:----------- |:------ |\n",
    "| monôme/binôme 1 | <span style=\"color:red\">Remplacer ici</span> | <span style=\"color:red\">et ici</span> |\n",
    "| binôme 2 | <span style=\"color:red\">Remplacer ici</span> | <span style=\"color:red\">et ici</span> |"
   ],
   "metadata": {
    "id": "wOQmdCRHTB16"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDyGj8DmXCJI"
   },
   "source": [
    "Ce tutoriel utilise l'apprentissage profond pour composer une image dans le style d'une autre image.\n",
    "(Vous avez déjà souhaité peindre comme Picasso ou Van Gogh ?)\n",
    "C'est ce qu'on appelle le *Neural Style Transfer* et la technique est décrite dans <a href=\"https://arxiv.org/abs/1508.06576\" class=\"external\">A Neural Algorithm of Artistic Style (Gatys et al., 2015)</a> .\n",
    "\n",
    "Dans ce tp, vous:\n",
    "- créérez l'algorithme du transfert de style à partir d'un réseau de neurones,\n",
    "- générerez des images _artistiques_ en utilisant votre algorithme.\n",
    "\n",
    "La plupart des algorithmes que vous avez étudiés optimisent une fonction de coût pour obtenir un ensemble de valeurs de paramètres. Dans le Neural Style Transfer, vous optimiserez une fonction de coût pour obtenir des valeurs de pixels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b3XwN9V1nvR"
   },
   "source": [
    "Le transfert de style neuronal est une technique d'optimisation utilisée pour:\n",
    "- considérer en entrée, deux images:\n",
    " - une image **(C)** de *contenu*\n",
    " - et une image **(S)** de *référence de style* (telle qu'une œuvre d'art d'un peintre célèbre)\n",
    "- et les fusionner de sorte que l'image de sortie **(G)** ressemble à l'image de contenu, mais \" peinte \" dans le style de l'image de référence de style.\n",
    "\n",
    "Cette opération est réalisée en optimisant l'image de sortie pour qu'elle corresponde aux statistiques de contenu de l'image de contenu et aux statistiques de style de l'image de référence de style. Ces statistiques sont extraites des images à l'aide d'un réseau de neurones convolutif (CNN). Par exemple, le contenu de la figure ci-dessous est une photo de paysage prise dans le parc national du Mont Rainier, dans la banlieue de Seattle, tandis que l'image de style est une peinture à l'huile sur le thème des chênes d'automne. Dans l'image synthétisée de sortie, les coups de pinceau à l'huile de l'image de style sont appliqués, ce qui permet d'obtenir des couleurs plus vives, tout en préservant la qualité de l'image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kb_UJY-jCEl"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1zQ4DbImMazHaTgbjmpnvc5GsG7L-lWlZ\" width=\"650px\"/>\n",
    "\n",
    "[Extrait de Dive into Deep Learning](https://d2l.ai/)\n",
    "\n",
    "Pour un autre exemple, prenons l'image de ce chien et la composition 7 de Wassily Kandinsky et posons nous la question: à quoi cela ressemblerait-il si Kandinsky décidait de peindre le tableau de ce chien exclusivement dans ce style ? Quelque chose comme ça ?\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
    "<tbody>\n",
    "  <td>\n",
    "     <img src=\"https://drive.google.com/uc?id=1m4UpjKznLNiIr4ntYrYFNcOAHpKs0g_d\" width=\"200px\"/>\n",
    "<img src=\"https://drive.google.com/uc?id=1v1yefr7dSJ3lopo566ntBON09j-uAZyq \" width=\"200px\"/>\n",
    "      <!--     [Yellow Labrador Looking](https://commons.wikimedia.org/wiki/File:YellowLabradorLooking_new.jpg), from Wikimedia Commons by [Elf](https://en.wikipedia.org/wiki/User:Elf). License [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/deed.en)\n",
    "      -->\n",
    " </td>\n",
    "  <td>\n",
    "<img src=\"https://drive.google.com/uc?id=14U1b9qLiDDleD-oug7_AaUTduhkFAWj5\" width=\"400px\"/>\n",
    "  </td>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8ajP_u73s6m"
   },
   "source": [
    "## 1. Setup (Configuration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Colab or not colab"
   ],
   "metadata": {
    "id": "ojlqQ7aySGUD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# common imports\n",
    "import sys,os,glob\n",
    "\n",
    "# Colab preamble\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "\n",
    "  # mount google drive directories\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "  # replace the ipynb_name (below) with the name of your jupyter notebook file\n",
    "\n",
    "  # ----------- Your code here --------------------->\n",
    "\n",
    "  ipynb_name = 'style_transfer_startercode.ipynb'\n",
    "\n",
    "  # ------------------------------------------------>\n",
    "\n",
    "  ipynb_name = glob.glob(os.getcwd() + '/**/' + ipynb_name, recursive = True)\n",
    "  code_folder = os.path.dirname(ipynb_name[0])\n",
    "\n",
    "  # change to the right folder\n",
    "  %cd \"$code_folder\"\n",
    "  !ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NgHX90IqSLsV",
    "outputId": "06f405e5-6b24-4d58-f803-91d3c09ce9a7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqxUicSPUOP6"
   },
   "source": [
    "### 1.2 Importer et configurer des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyftRTSMuwue"
   },
   "outputs": [],
   "source": [
    "# common imports\n",
    "import numpy as np\n",
    "\n",
    "# display imports\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "matplotlib.rc('animation', html='jshtml') # To get smooth animations\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12, 12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "import PIL.Image\n",
    "# import time\n",
    "\n",
    "\n",
    "# machine learning packages\n",
    "import tensorflow as tf\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IN_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "elif len(tf.config.list_physical_devices('GPU')) > 1:\n",
    "  # a décommenter si problème avec le GPU de votre machine\n",
    "  physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "  for gpu in physical_devices:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "\n",
    "# Load compressed models from tensorflow_hub\n",
    "import tensorflow_hub as hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "\n",
    "# import connected to display\n",
    "import IPython.display as display\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "880WzWSkaKlt"
   },
   "source": [
    "### 1.3 fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GM6VEGrGLh62"
   },
   "outputs": [],
   "source": [
    "# fonction qui permet d'afficher une image à partir des sorties de tf\n",
    "def tensor_to_image(tensor):\n",
    "  tensor = tensor*255\n",
    "  tensor = np.array(tensor, dtype=np.uint8)\n",
    "  if np.ndim(tensor)>3:\n",
    "    assert tensor.shape[0] == 1\n",
    "    tensor = tensor[0]\n",
    "  return PIL.Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TLljcwv5qZs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fonction pour charger une image et limiter sa dimension maximale à 512 pixels.\n",
    "def load_img(path_to_img):\n",
    "  max_dim = 512\n",
    "  img = tf.io.read_file(path_to_img)\n",
    "  img = tf.image.decode_image(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "  long_dim = max(shape)\n",
    "  scale = max_dim / long_dim\n",
    "\n",
    "  new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "  img = tf.image.resize(img, new_shape)\n",
    "  img = img[tf.newaxis, :]\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBX-eNT8PAK_"
   },
   "outputs": [],
   "source": [
    "# fonction d'affichage d'une image\n",
    "def imshow(image, title=None):\n",
    "  if len(image.shape) > 3:\n",
    "    image = tf.squeeze(image, axis=0)\n",
    "\n",
    "  plt.imshow(image)\n",
    "  if title:\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rvo9XQjNaKlx"
   },
   "source": [
    "### 1.3 images de contenu et de style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeXebYusyHwC"
   },
   "source": [
    "**Choisissez une image de style et une image de contenu : vous pouvez garder les images proposées dans un premier temps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqc0OJHwyFAk"
   },
   "outputs": [],
   "source": [
    "# chemin du répertoire des fichiers de contenus\n",
    "content_folder = './contents/'\n",
    "\n",
    "# chemin du fichier de contenu\n",
    "content_path = content_folder+'brest3.jpg'\n",
    "\n",
    "# chemin du répertoire des fichiers de styles\n",
    "style_folder = './styles/'\n",
    "\n",
    "# chemin du fichier de style\n",
    "style_path = style_folder+'wave.jpg'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xE4Yt8nArTeR"
   },
   "source": [
    "## 2. Visualiser les entrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UWQmeEaiKkP",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "outputId": "072bc467-6100-4e2a-ee4c-d6ea19242676"
   },
   "outputs": [],
   "source": [
    "content_image = load_img(content_path)\n",
    "style_image = load_img(style_path)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "imshow(content_image, 'Content Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "imshow(style_image, 'Style Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMzChXSlKTA2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Fast Style Transfer en utilisant le modèle de TF_Hub\n",
    "\n",
    "Il existe un hub (tensorflow_hub) regroupant les différents modèles pré-entrainés de réseau de neurones pouvant être utilisés par tensorflow. Avant de voir et programmer l'algorithme, vous pouvez charger le [modèle associé au tranfert de style](https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2).\n",
    "\n",
    "Pour cela, il suffit d'exécuter les trois lignes suivantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYSLexgRKSh-",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "outputId": "aabac273-2606-49d8-8d94-c01e972565e2"
   },
   "outputs": [],
   "source": [
    "# chargement du modèle\n",
    "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
    "\n",
    "# application du modèle pour une image de contenu et de style\n",
    "stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\n",
    "\n",
    "# plot image\n",
    "tensor_to_image(stylized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEwZ7FlwrjoZ"
   },
   "source": [
    "## 4. Principe de la méthode\n",
    "\n",
    "Le transfert de style neuronal (NST) utilise un réseau convolutif préalablement entrainé. L'idée d'utiliser un réseau pré-entrainé sur une tâche différente et de l'appliquer à une nouvelle tâche est appelée __apprentissage par transfert__. Vous avez déjà rencontré ce type d'apprentissage lors de l'apprentissage d'un modèle de classification par __fine tuning__.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1dt3af2pYZbiwXi8lCcEvA7NHgjFvzqWO\" width=\"450px\"/>\n",
    "\n",
    "La figure ci-dessus illustre la méthode de transfert de style basée sur CNN à l'aide d'un exemple simplifié.\n",
    "- **Initialiser** l'image synthétisée (par exemple random ou par le contenu).\n",
    " - cette image synthétisée est un ensemble de pixels représentant les **variables** qui seront mises à jour pendant le processus de transfert de style, c'est-à-dire que ce sont les seuls paramètres du modèle qui doivent être mis à jour pendant l'apprentissage.\n",
    "- **Choisir un modèle CNN pré-entraîné** pour extraire les caractéristiques (features) de l'image.\n",
    "- **Fixer les paramètres** de ce modèle pendant l'apprentissage.\n",
    "- **Choisir la sortie de certaines de ces couches** en tant que caractéristiques de contenu ou de style. Un CNN utilise plusieurs couches pour extraire les caractéristiques hiérarchiques des images.\n",
    "- **Calculer la fonction de coût du transfert de style** par propagation avant (direction des flèches pleines) et **Mettre à jour les paramètres** du modèle (l'image synthétisée en sortie) par back-propagation (direction des flèches pointillées). La fonction de coût couramment utilisée dans le transfert de style se compose de **trois parties** :\n",
    "  - (i) le **coût de contenu** rend l'image synthétisée et l'image de contenu proches pour les caractéristiques de contenu\n",
    "  - (ii) le **coût de style** rend l'image synthétisée et l'image de style proches pour les caractéristiques de style\n",
    "  - (iii) le **coût de variation totale** permet de réduire le bruit dans l'image synthétisée en sortie.\n",
    "- Enfin, lorsque l'apprentissage du modèle est terminé, nous avons **généré l'image synthétisée finale**.\n",
    "\n",
    "Dans l'exemple de la figure, la deuxième couche du réseau de neurones convolutionnel pré-entraîné produit les caractéristiques de contenu, et les première et troisième couches produisent les caractéristiques de style.\n",
    "En suivant l'article original du NST (https://arxiv.org/abs/1508.06576), nous utiliserons le réseau VGG. Plus précisément, nous utiliserons le VGG-19, une version à 19 couches du réseau VGG. Ce modèle a déjà été entraîné sur la très grande base de données ImageNet, et a donc appris à reconnaître une variété de caractéristiques de bas niveau (aux premières couches) et de haut niveau (aux couches plus profondes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "bYRS22VMaKl0"
   },
   "source": [
    "## 5 Chargement du modèle préentrainé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP_7zrziuiJk"
   },
   "source": [
    "**Question: Chargez le modèle [VGG19](https://keras.io/api/applications/vgg/#vgg19-function) et testez-le sur l'image de contenu pour vous assurer qu'il est utilisé correctement :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMbzrr7BCTq0",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5a6d3f39-330a-4947-a066-7f8bfac76203"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "\n",
    "# chargez le modèle vgg19 avec son classifieur (include_top=True)\n",
    "# hint: regardez comment on a fait pour le fine tuning\n",
    "# vgg=...\n",
    "\n",
    "# prétraitez l'image de contenu par le modèle (i.e. preprocess_input)\n",
    "# hint: regardez comment on a fait pour le fine tuning\n",
    "# hint2: x=...(content_image*255)\n",
    "\n",
    "\n",
    "# utilisez tf.image.resize pour redimensionner l'image en 224x244 pixels\n",
    "# uniquement utile pour la prédiction avec classifieur\n",
    "# x = ...\n",
    "\n",
    "# testez l'image de contenu par le modèle\n",
    "# predicted_probabilities = ...\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "print('Le nombre de classe est de: {}'.format(predicted_probabilities.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Rz4kAGCaKl1"
   },
   "source": [
    "On peut décoder ces probabilités pour découvrir leurs classes correspondantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_FyCm0dYnvl",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ce5a081f-eed3-4b57-8c46-378f90bdf044"
   },
   "outputs": [],
   "source": [
    "predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(predicted_probabilities.numpy())[0]\n",
    "[(class_name, prob) for (number, class_name, prob) in predicted_top_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljpoYk-0f6HS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question: Chargez le modèle [VGG19](https://keras.io/api/applications/vgg/#vgg19-function) sans son classifieur et listez les noms des couches**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yh_AV6220ebD",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "81594b6a-d998-4a97-f09d-98fb2521a2b3"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "\n",
    "# chargez le modèle vgg19 sans son classifieur\n",
    "# vgg = ...\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "# affichage des noms des layers\n",
    "for (ilayer,layer) in enumerate(vgg.layers):\n",
    "  print('layer {}: {}'.format(ilayer,layer.name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "hYdHqrYWaKl3"
   },
   "source": [
    "## 6. Définir la fonction de coût (la tâche à réaliser)\n",
    "\n",
    "Comme évoqué précédemment, la fonction de coût couramment utilisée dans le transfert de style se compose de **trois parties** :\n",
    "  - (i) le **coût de contenu** $J_{content}(C,G)$ rend l'image synthétisée et l'image de contenu proches pour les caractéristiques de contenu\n",
    "  - (ii) la **coût de style** $J_{style}(S,G)$ rend l'image synthétisée et l'image de style proches pour les caractéristiques de style\n",
    "  - (iii) la **coût de variation totale** permet de réduire le bruit dans l'image synthétisée en sortie. Pour le moment, nous n'en tiendrons pas compte.\n",
    "\n",
    "- La fonction de coût totale est alors $J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$.\n",
    "\n",
    "\n",
    "Comme vous l'avez vu dans les vidéos et dans le préambule, le choix de $J_{content}(C,G)$ et de $J_{style}(S,G)$ consiste premièrement à choisir les couches d'activation (après les non-linéarités) à partir desquelles on va imiter les sorties (features) pour `coller` au contenu ou au style.\n",
    "\n",
    "Comme vous l'avez vu dans les vidéos, les premières couches en partant de la couche d'entrée du réseau (moins profondes, en amont du réseau) d'un CNN ont tendance à détecter les caractéristiques de bas niveau telles que les bords et les textures simples, et les dernières couches (plus profondes, en aval du réseau) ont tendance à détecter les caractéristiques de plus haut niveau telles que des textures plus complexes (des parties d'objet comme les *roues* ou les *yeux*) ou même les classes d'appartenance d'objet.\n",
    "\n",
    "Alors pourquoi ces sorties intermédiaires de notre réseau de classification d'images pré-entraîné nous permettent-elles de définir des représentations de style et de contenu ?\n",
    "\n",
    "À un haut niveau, pour qu'un réseau puisse effectuer une classification d'images (ce pour quoi ce réseau a été entraîné), il doit comprendre l'image. Cela nécessite de prendre l'image brute comme entrée et de construire une représentation interne qui convertit les pixels de l'image brute en une compréhension des caractéristiques complexes présentes dans l'image.\n",
    "\n",
    "C'est également une des raisons pour lesquelles les réseaux neuronaux convolutifs sont capables de généraliser : ils sont capables de capturer les invariances et les caractéristiques définissant les classes (par exemple, chats vs chiens) qui sont agnostiques/indépendantes au bruit de fond et autres nuisances. Ainsi, quelque part entre l'entrée de l'image brute dans le modèle et l'étiquette de classification de sortie, le modèle sert d'extracteur de caractéristiques complexes. En accédant aux couches intermédiaires du modèle, vous êtes en mesure de décrire le contenu et le style des images d'entrée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nyInQIhaKl3"
   },
   "source": [
    "### 6.1 Choisir la fonction de coût de contenu  $J_{content}(C,G)$\n",
    "\n",
    "\n",
    "#### 6.1.1 **Choix des couches d'activation de contenu**\n",
    "\n",
    "Nous aimerions que l'image \"générée\" G ait un contenu similaire à celui de l'image d'entrée C. En pratique, vous obtiendrez les résultats les plus agréables visuellement si vous choisissez une couche au milieu du réseau - ni trop proche des entrées, ni trop profonde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt-tASys0eJv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question: Choisissez des couches intermédiaires du réseau pour représenter le contenu de l'image :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArfX_6iA0WAX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "# choisissez la liste des layers de contenu (dans un premier temps, garder ce choix)\n",
    "# content_layers = ['...']\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "# variable utile pour la suite\n",
    "num_content_layers = len(content_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqQEdOpMaKl4"
   },
   "source": [
    "#### 6.1.2 Extraire les features de contenu\n",
    "Les réseaux de `tf.keras.applications` sont conçus de manière à ce que vous puissiez facilement extraire les valeurs des couches intermédiaires à l'aide de l'API fonctionnelle de Keras.\n",
    "\n",
    "Pour définir un modèle d'extraction de features à l'aide de l'API fonctionnelle, spécifiez les entrées et les sorties : `model = Model(inputs, outputs)`\n",
    "\n",
    "La fonction suivante construit un modèle VGG19 qui renvoie une liste de sorties de couches intermédiaires `layer_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "k6cemc-haKl4"
   },
   "outputs": [],
   "source": [
    "def vgg_layers(layer_names):\n",
    "    \"\"\" Creates a vgg model that returns a list of intermediate output values.\"\"\"\n",
    "    # Charger le modèle vgg19 préentrainé sur les données imagenet\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "\n",
    "    # fixer les paramètres pour l'apprentissage\n",
    "    vgg.trainable = False\n",
    "\n",
    "    # liste des sorties des couches souhaitées\n",
    "    outputs = [vgg.get_layer(name).output for name in layer_names]\n",
    "\n",
    "    # construction du nouveau modèle\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbaIvZf5wWn_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Et pour créer et tester le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkyvPpBHSfVi",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "38aa5e52-819c-47b5-db5c-6e9435100c06"
   },
   "outputs": [],
   "source": [
    "# création d'un modèle d'extraction de features de style\n",
    "content_extractor = vgg_layers(content_layers)\n",
    "\n",
    "# pretraitement de l'image\n",
    "content_image_p = content_image*255\n",
    "\n",
    "# Extraction des features de style pour l'image style_image\n",
    "content_outputs = content_extractor(content_image*255)\n",
    "\n",
    "# Estimation des statistiques pour les sorties de chaque couche\n",
    "for name, output in zip(content_layers, content_outputs):\n",
    "    print('------------------------>')\n",
    "    print(name)\n",
    "    print(\"  shape: \", output.numpy().shape)\n",
    "    print(\"  min: \", output.numpy().min())\n",
    "    print(\"  max: \", output.numpy().max())\n",
    "    print(\"  mean: \", output.numpy().mean())\n",
    "    print()\n",
    "\n",
    "# plt.figure(); plt.imshow(content_outputs[0][0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "8_VFa3IiaKl5"
   },
   "source": [
    "#### 6.1.3 **Choix de la fonction de coût de contenu**\n",
    "\n",
    "Supposons donc que vous ayez choisi d'utiliser une couche $l$ cachée particulière.\n",
    "\n",
    "- Présentez l'image C en entrée du réseau VGG pré-entraîné, et appliquez le modèle (forward propagation).\n",
    "\n",
    "Soit $a^{[l](C)}$ les activations de la couche cachée dans la couche que vous avez choisie. Ce sera un tenseur $n_H \\times n_W \\times n_C$.\n",
    "\n",
    "- Répétez ce processus avec l'image G : définissez G comme entrée, et exécutez la forward propagation. Soit $a^{[l](G)}$ l'activation de la couche cachée correspondante. Nous définirons la fonction de coût du contenu comme suit :\n",
    "\n",
    "$$J^{[l]}_{content}(C,G) =  \\frac{1}{4 \\times n_H \\times n_W \\times n_C}\\sum _{ \\text{all entries}} (a^{[l](C)} - a^{[l](G)})^2\\tag{1} $$\n",
    "\n",
    "Ici, $n_H, n_W$ et $n_C$ sont la hauteur, la largeur et le nombre de canaux de la couche cachée que vous avez choisie, et apparaissent dans un terme de normalisation dans le coût. Pour plus de clarté, notez que $a^{[l](C)}$ et $a^{[l](G)}$ sont les volumes correspondant aux activations d'une couche cachée.\n",
    "\n",
    "Similaire à la loss function en régression linéaire, la fonction de coût de contenu mesure la différence entre les features de l'image de contenu et les features de l'image synthétisée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "metZdj3XaKl5"
   },
   "source": [
    "**Question: Codez la fonction de coût de contenu pour une couche (layer)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALNuL09UaKl5"
   },
   "outputs": [],
   "source": [
    "def content_loss_layer(a_C, a_G):\n",
    "\n",
    "# ----------- Your code here --------------------->\n",
    "\n",
    "    # Retrouver les dimensions de a_G (≈1 line, get_shape, as_list)\n",
    "    # n_H, n_W, n_C = ...\n",
    "\n",
    "    # calcul de la fonction de cout (tf.reduce_sum)\n",
    "    # rst = ...\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "    return rst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvgHuig5aKl6"
   },
   "source": [
    "**Testez la fonction `content_loss_layer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWHKQP4kaKl6",
    "outputId": "40aa0ee8-a802-4b42-db77-d22f16ac6cd3"
   },
   "outputs": [],
   "source": [
    "# on fixe l'aléatoire\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "\n",
    "# choix de a_C et a_G\n",
    "a_C = content_outputs[0]\n",
    "a_G = tf.random.normal(a_C.shape, mean=1, stddev=4)\n",
    "\n",
    "# calcul du coût de contenu\n",
    "J_content = content_loss_layer(a_C, a_G)\n",
    "print(\"J_content = \" + str(J_content.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z837-wRWaKl6"
   },
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **J_content**\n",
    "        </td>\n",
    "        <td>\n",
    "           24109.83\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "O5ko5SFXaKl7"
   },
   "source": [
    "**La fonction suivante calcul le coût de contenu pour un nombre quelconque de layers **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "iNv6xoKTaKl7"
   },
   "outputs": [],
   "source": [
    "def content_cost(content_targets, content_outputs):\n",
    "\n",
    "    tmp = [content_loss_layer(content_target, content_output)\n",
    "                        for content_target, content_output in zip(content_targets, content_outputs)]\n",
    "    J_content = tf.add_n(tmp)\n",
    "\n",
    "\n",
    "    return J_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "nfnRvYaiaKl7"
   },
   "source": [
    "**Pour tester la fonction, nous allons d'abord créer un objet permettant d'extraire les features de contenu:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "5jgKxgfbaKl8"
   },
   "outputs": [],
   "source": [
    "class ContentModel(tf.keras.models.Model):\n",
    "  def __init__(self, content_layers):\n",
    "    super(ContentModel, self).__init__()\n",
    "\n",
    "    self.vgg = vgg_layers(content_layers) # le modèle sort les features de contenu\n",
    "    self.vgg.trainable = False # on fixe les paramètres pour l'apprentissage\n",
    "    self.content_layers = content_layers # nom des couches de contenu\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    # preprocess inputs\n",
    "    \"Expects float input in [0,1]\"\n",
    "    inputs = inputs*255.0\n",
    "    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
    "\n",
    "    # forward pass\n",
    "    content_outputs = self.vgg(preprocessed_input)\n",
    "\n",
    "    return content_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN7FlkDnaKl8"
   },
   "source": [
    "Ce qui permet de tester la fonction content cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnDVfh6raKl8",
    "outputId": "8c9d59e3-9701-4712-ccf3-2a8a1e373814"
   },
   "outputs": [],
   "source": [
    "# création du modèle d'extraction de features de contenu\n",
    "content_extractor = ContentModel(content_layers)\n",
    "\n",
    "# extraction de features de contenu\n",
    "content_targets = content_extractor(content_image)\n",
    "\n",
    "# features de contenu cible\n",
    "content_outputs = [tf.random.normal(content_output.shape) for i, content_output in enumerate(content_outputs)]\n",
    "\n",
    "# mesures de la similarité entre les deux via la fonction de cout\n",
    "content_cost(content_outputs, content_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UK2tJM8PaKl8"
   },
   "source": [
    "### 6.2 Choisir la fonction de coût de style $J_{style}(S,G)$\n",
    "\n",
    "#### 6.2.1 **Choix des couches d'activation de style**\n",
    "\n",
    "Pour la fonction de coût de style, il s'agit d'imiter des informations locales et globales et ainsi avoir des features venant des différents niveaux d'abstraction du réseau.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "OiGUKV7CaKl9"
   },
   "source": [
    "**Question: Choisissez des couches intermédiaires du réseau pour représenter le style de l'image :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "u6OqvuRyaKl9"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "\n",
    "# choisissez la liste des layers de style\n",
    "style_layers = ['...', '...']\n",
    "\n",
    "# variable utile pour la suite\n",
    "num_style_layers = len(style_layers)\n",
    "\n",
    "# ------------------------------------------------>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AZfCRfnaKl9"
   },
   "source": [
    "#### 6.2.2 Extraire les features de style\n",
    "De la même manière, la fonction `vgg_layers` définie précédemment permet d'extraire les features de style à partir du modèle suivant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBF5mKupaKl9",
    "outputId": "523b0627-502f-4997-ab1f-ec7d5ca7866c"
   },
   "outputs": [],
   "source": [
    "# création d'un modèle d'extraction de features de style\n",
    "style_extractor = vgg_layers(style_layers)\n",
    "\n",
    "# Extraction des features de style pour l'image style_image\n",
    "style_outputs = style_extractor(style_image*255)\n",
    "\n",
    "# Estimation des statistiques pour les sorties de chaque couche\n",
    "for name, output in zip(style_layers, style_outputs):\n",
    "    print('------------------------>')\n",
    "    print(name)\n",
    "    print(\"  shape: \", output.numpy().shape)\n",
    "    print(\"  min: \", output.numpy().min())\n",
    "    print(\"  max: \", output.numpy().max())\n",
    "    print(\"  mean: \", output.numpy().mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ijn4kyNaKl9"
   },
   "source": [
    "**Choix de la fonction de style**\n",
    "\n",
    "Il s'avère que le style d'une image peut être décrit par les moyennes et les corrélations entre les différentes cartes de caractéristiques (feature map ou activation map).\n",
    "\n",
    "\n",
    "En algèbre linéaire, la matrice de Gram $GM$ d'un ensemble de vecteurs $(v_{1},\\dots ,v_{n})$ est la matrice des produits scalaires, dont les entrées sont ${\\displaystyle GM_{ij} = v_{i}^T v_{j}/(2 \\times n_H \\times n_W})$. En d'autres termes, $GM_{ij}$ compare la similarité entre $v_i$ et $v_j$ : s'ils sont très similaires, le produit scalaire est élevé, et donc $G_{ij}$ est élevé.\n",
    "\n",
    "Notez que plus le produit $n_H \\cdot n_W$ est grand, plus les résultats dans la matrice de Gram sont grands. C'est pourquoi, il y a une normalisation par $2 \\times n_H \\times n_W$.\n",
    "\n",
    "Vous pouvez calculer la matrice de Gram en multipliant la matrice de filtres \"vectorisée\" (flatten) par leur transposée :\n",
    "<img src=\"imgs/NST_GM.png\" style=\"width:900px;height:300px;\">\n",
    "\n",
    "Le résultat est une matrice de dimension $(n_C,n_C)$ où $n_C$ est le nombre de filtres. La valeur $GM_{ij}$ mesure la similarité entre les activations du filtre $i$ et les activations du filtre $j$.\n",
    "\n",
    "Une partie importante de la matrice de Gram est que les éléments diagonaux $GM_{ii}$ mesurent également l'activité du filtre $i$. Par exemple, supposons que le filtre $i$ détecte des textures verticales dans l'image. Alors $GM_{ii}$ mesure la fréquence des textures verticales dans l'image dans son ensemble : Si $GM_{ii}$ est grand, cela signifie que l'image a beaucoup de textures verticales.\n",
    "\n",
    "En capturant l'importance des différents types de caractéristiques ($GM_{ii}$), ainsi que le nombre de caractéristiques différentes présentes ensemble ($GM_{ij}$), la matrice de style $G$ mesure le style d'une image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "UDluYvvnaKl_"
   },
   "source": [
    "La fonction suivante permet de calculer la matrice de Gram pour une matrice en entrée ou un tenseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAy1iGPdoEpZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gram_matrix(input_tensor):\n",
    "\n",
    "    # produit matriciel sur les éléments ij\n",
    "    GM = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "\n",
    "    # normalisation\n",
    "    input_shape = tf.shape(input_tensor)\n",
    "    num_locations = 2*tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
    "    GM /= num_locations\n",
    "\n",
    "    return GM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "VcnvwFlbaKl_"
   },
   "source": [
    "**Pour tester cette fonction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKytAWPdaKl_",
    "outputId": "16e7394e-1fde-4876-895f-c0bc1f3064b3"
   },
   "outputs": [],
   "source": [
    "# test de la fonction\n",
    "tf.random.set_seed(1)\n",
    "A = tf.random.normal([1, 3, 3,2*1], mean=1, stddev=4)\n",
    "GM = gram_matrix(A)\n",
    "\n",
    "print(\"GM = \" + str(GM.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unWdGOwxaKmA"
   },
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **GM**\n",
    "        </td>\n",
    "        <td>\n",
    "           [[[4.4117     0.05906195]\n",
    "  [0.05906195 5.7787175 ]]]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YW6YgjiaKmA"
   },
   "source": [
    "Après avoir calculé la matrice de style (matrice de Gram), votre objectif sera de minimiser la distance entre la matrice de Gram de l'image \"style\" S et celle de l'image \"générée\" G. Pour l'instant, nous n'utilisons qu'une seule couche cachée $a^{[l]}$, et le coût de style correspondant pour cette couche est défini comme suit :\n",
    "\n",
    "$$J_{style}^{[l]}(S,G) = \\frac{1}{{n_C}^2} \\sum _{i=1}^{n_C}\\sum_{j=1}^{n_C}(GM^{(S)}_{ij} - GM^{(G)}_{ij})^2\\tag{2} $$\n",
    "\n",
    "où $GM^{(S)}$ et $GM^{(G)}$ sont respectivement les matrices de Gram de l'image \"style\" et de l'image \"générée\", calculées en utilisant les activations de la couche cachée $l$.  \n",
    "\n",
    "Notez que la hauteur et la largeur de la matrice de Gram sont toutes les deux le nombre de canaux $n_C$. Pour permettre à la perte de style de ne pas être affectée par ces valeurs, la fonction de coût du style $J_{style}^{[l]}(S,G)$ divise la matrice de Gram par le nombre de ses éléments, c'est-à-dire $n_c $. Avec la différence au carré, on obtient ${n_C}^2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-3s6jnJaKmA"
   },
   "source": [
    "**Question: Calculez la fonction de coût pour une couche (layer) l**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fahmzjqCaKmA"
   },
   "outputs": [],
   "source": [
    "def style_cost_layer(a_S, a_G):\n",
    "\n",
    "# ----------- Your code here --------------------->\n",
    "    # Retrouver les dimensions de a_G (≈1 line) get_shape, as_list\n",
    "    # n_b, n_H, n_W, n_C =...\n",
    "\n",
    "    # Computing gram_matrices for both images S and G (≈2 lines)\n",
    "    # GS = ...\n",
    "    # GG = ...\n",
    "\n",
    "    # Calculer la fonction de coût du style (≈1 ligne)\n",
    "    # J_style_layer = ...\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "    return J_style_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-PfbZjjaKmB"
   },
   "source": [
    "**Test de la fonction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUEDFq7jaKmB",
    "outputId": "93ebc615-7f3a-4b15-f3b5-e5f777122b6f"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "a_S = tf.random.normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "a_G = tf.random.normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "\n",
    "J_style_layer = style_cost_layer(a_S, a_G)\n",
    "\n",
    "print(\"J_style_layer = \" + str(J_style_layer.numpy()))\n",
    "\n",
    "\n",
    "# test de la fonction avec style_outputs\n",
    "a_S = style_outputs[0]\n",
    "a_G = tf.random.normal(style_outputs[0].shape, mean=1, stddev=4)\n",
    "\n",
    "J_style_layer = style_cost_layer(a_S, a_G)\n",
    "print(\"J_style_layer = \" + str(J_style_layer.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKV2DWlKaKmB"
   },
   "source": [
    "**Expected Outputs**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **J_style_layer**\n",
    "        </td>\n",
    "        <td>\n",
    "           14.017806\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **J_style_layer**\n",
    "        </td>\n",
    "        <td>\n",
    "           8938998.0\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSQKofiHaKmB"
   },
   "source": [
    "**La fonction suivante calcule le coût de style pour un nombre quelconque de layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YVOyRauAaKmB"
   },
   "outputs": [],
   "source": [
    "def style_cost(style_targets, style_outputs):\n",
    "\n",
    "    tmp = [style_cost_layer(style_targets[i],style_output) for i, style_output in enumerate(style_outputs)]\n",
    "    J_style = tf.add_n(tmp)\n",
    "\n",
    "    return J_style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "ApDgzQgnaKmC"
   },
   "source": [
    "**Pour tester la fonction, nous allons d'abord créer un objet permettant d'extraire les features de style:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "fiwYajCKaKmC"
   },
   "outputs": [],
   "source": [
    "class StyleModel(tf.keras.models.Model):\n",
    "  def __init__(self, style_layers):\n",
    "    super(StyleModel, self).__init__()\n",
    "\n",
    "    self.vgg = vgg_layers(style_layers) # le modèle sort les features de style puis de contenu\n",
    "    self.vgg.trainable = False # on fixe les paramètres pour l'apprentissage\n",
    "    self.style_layers = style_layers # nom des couches de style\n",
    "    self.num_style_layers = len(style_layers)\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    # preprocess inputs\n",
    "    \"Expects float input in [0,1]\"\n",
    "    inputs = inputs*255.0\n",
    "    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
    "\n",
    "    # forward pass\n",
    "    style_outputs = self.vgg(preprocessed_input)\n",
    "\n",
    "    return style_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "bKiQPGNOaKmC"
   },
   "source": [
    "**Test de la fonction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3pitvEvaKmD",
    "outputId": "7dcc52fd-0f8d-4629-8eb0-51d2d1469caa"
   },
   "outputs": [],
   "source": [
    "# création du modèle d'extraction de feature de style\n",
    "style_extractor = StyleModel(style_layers)\n",
    "\n",
    "# Extraction de feature de style pour l'image de style\n",
    "style_targets = style_extractor(style_image)\n",
    "\n",
    "# Extraction de feature de style pour l'image de contenu\n",
    "style_outputs = style_extractor(content_image)\n",
    "\n",
    "# Similarité entre les features\n",
    "style_cost(style_targets,style_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "lJha_FwPaKmD"
   },
   "source": [
    "**Expected Outputs**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            style_cost\n",
    "        </td>\n",
    "        <td>\n",
    "          19937085000.0\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "IgTqWL9GaKmD"
   },
   "source": [
    "### 6.3 Définir la fonction de coût totale $J(G)$\n",
    "\n",
    "Enfin, créons une fonction de coût totale qui minimise à la fois le coût du style et celui du contenu. La formule est la suivante :\n",
    "$$J(G) = \\alpha / numContentLayers \\times J_{content}(C,G) + \\beta  / numStyleLayers \\times J_{style}(S,G)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skWoIQN-aKmD"
   },
   "source": [
    "Fixons d'abord arbitrairement les poids de chaque contribution. Vous pourrez essayer différentes valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dt4pxarvA4I4"
   },
   "outputs": [],
   "source": [
    "alpha = style_weight = 1e-2 / num_style_layers\n",
    "beta = content_weight = 1e2 / num_content_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "9gjmj05yaKmE"
   },
   "source": [
    "**Question: codez cette fonction de coût totale:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ggx2Na8oROH"
   },
   "outputs": [],
   "source": [
    "def style_content_loss(style_outputs, content_outputs):\n",
    "\n",
    "# ----------- Your code here --------------------->\n",
    "\n",
    "# terme de style pondéré\n",
    "#     style_loss = ...\n",
    "\n",
    "    # terme de contenu pondéré\n",
    "#     content_loss = ...\n",
    "\n",
    "    # somme\n",
    "#     loss = ...\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "    return loss, style_loss, content_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dj--wZExaKmE"
   },
   "source": [
    "**Test de la fonction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0_B7HnqaKmE",
    "outputId": "96049248-dd92-415e-81d9-4bd031d5b6cb"
   },
   "outputs": [],
   "source": [
    "# extraction des features\n",
    "style_targets = style_extractor(style_image)\n",
    "content_targets = content_extractor(content_image)\n",
    "\n",
    "style_outputs = [tf.random.normal(style_target.shape) for i, style_target in enumerate(style_targets)]\n",
    "content_outputs = [tf.random.normal(content_target.shape) for i, content_target in enumerate(content_targets)]\n",
    "\n",
    "\n",
    "loss, style_loss, content_loss = style_content_loss(style_outputs, content_outputs)\n",
    "print(loss, style_loss, content_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5b56jI2aKmF"
   },
   "source": [
    "**Expected Outputs**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            loss\n",
    "        </td>\n",
    "        <td>\n",
    "           91000080.0\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            style_loss\n",
    "        </td>\n",
    "        <td>\n",
    "           89262130.0\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            content_loss\n",
    "        </td>\n",
    "        <td>\n",
    "           1737952.5\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "etWvrLW-aKmF"
   },
   "source": [
    "## 7. Apprentissage par optimisation de la fonction de coût totale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9r8Lyjb_m0u"
   },
   "source": [
    "Avec cet extracteur de style et de contenu, vous pouvez maintenant mettre en œuvre l'algorithme de transfert de style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "6fQ3776YaKmG"
   },
   "source": [
    "### 7.1 Définition des valeurs cibles de style et de contenu\n",
    "\n",
    "**Question: Définissez vos valeurs cibles de style et de contenu :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgkNOnGUFcKa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "\n",
    "# style_targets = ...\n",
    "# content_targets = ...\n",
    "\n",
    "# ------------------------------------------------>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "gXaJcLS_aKmG"
   },
   "source": [
    "### 7.2 Initialisation de l'image à optimiser\n",
    "\n",
    "Définissez une `tf.Variable` pour contenir l'image à optimiser. Pour que cela soit rapide, initialisez-la avec l'image du contenu (la `tf.Variable` doit avoir la même forme que l'image du contenu) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0vKxF8ZO6G8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = tf.Variable(content_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6L8ojmn_6rH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Puisqu'il s'agit d'une image à virgule flottante (float), définissez une fonction pour maintenir les valeurs des pixels entre 0 et 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdgpTJwL_vE2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clip_0_1(image):\n",
    "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBU5RFpcAo7W",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 7.3 Choisir un optimiseur\n",
    "\n",
    "**Question: Créer un optimiseur. L'article original recommande LBFGS, mais `Adam` fonctionne bien aussi. (Fixer le learning_rate à une valeur de 0.02)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4XZjqUk_5Eu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "\n",
    "# opt_fcn = ....\n",
    "\n",
    "# ------------------------------------------------>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "l5S-HHQeaKmH"
   },
   "source": [
    "### 7.4 Forward and back propagation et descente de gradients\n",
    "\n",
    "Plutôt que la fonction `fit` de `tf.keras`, nous allons utiliser `tf.GradientTape` pour réaliser la descente de gradient.\n",
    "PS: notez que la fonction `fit` intègre cette manière de faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0t0umkajFIuh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history_total_loss = []\n",
    "history_style_loss = []\n",
    "history_content_loss = []\n",
    "\n",
    "# @tf.function() # si décommenter permet une implémentation plus rapide mais pas le débuggage\n",
    "def train_step(image):\n",
    "\n",
    "    # forward pass avec enregistrement de toutes les activations\n",
    "    with tf.GradientTape() as tape:\n",
    "        # extraction des features pour l'image à synthétiser\n",
    "        style_outputs = style_extractor(image)\n",
    "        content_outputs = content_extractor(image)\n",
    "\n",
    "        # calcul de la fonction de coût\n",
    "        loss, style_loss, content_loss = style_content_loss(style_outputs,content_outputs)\n",
    "\n",
    "    # calcul des gradients par rétropropagation\n",
    "    grad = tape.gradient(loss, image)\n",
    "\n",
    "    # application des gradients aux paramètres (ici l'image) de la manière classique d'une descente de gradient\n",
    "    opt_fcn.apply_gradients([(grad, image)])\n",
    "\n",
    "    # mise à jour de l'image\n",
    "    image.assign(clip_0_1(image))\n",
    "\n",
    "    # mise à jour de l'historique\n",
    "    history_total_loss.append(loss)\n",
    "    history_style_loss.append(style_loss)\n",
    "    history_content_loss.append(content_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FHMJq4UBRIQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Maintenant, exécutez quelques étapes pour tester :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y542mxi-O2a2",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "outputId": "e78f2035-ccac-4be5-ab1f-b4850a3e6eaa"
   },
   "outputs": [],
   "source": [
    "train_step(image)\n",
    "train_step(image)\n",
    "train_step(image)\n",
    "tensor_to_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNzE-mTbBVgY"
   },
   "source": [
    "Puisque ça marche, effectuez une optimisation plus longue :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQW1tXYoLbUS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "outputId": "d335f505-cecb-42da-ec91-bf7f50add966"
   },
   "outputs": [],
   "source": [
    "# démarrage du chrono\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# paramètres\n",
    "epochs = 10\n",
    "steps_per_epoch = 100\n",
    "\n",
    "# boucle sur les épochs\n",
    "step = 0\n",
    "for n in range(epochs):\n",
    "    for m in range(steps_per_epoch):\n",
    "        step += 1\n",
    "\n",
    "        # un pas de descente de gradient\n",
    "        train_step(image)\n",
    "\n",
    "        # display\n",
    "        print(\".\", end='', flush=True)\n",
    "\n",
    "    # display\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(tensor_to_image(image))\n",
    "    print(\"Train step: {}\".format(step))\n",
    "\n",
    "# arret du chrono et affichage\n",
    "end = time.time()\n",
    "print(\"Total time: {:.1f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADXu5gAnaKmJ"
   },
   "source": [
    "**On peut afficher également l'évolution du coût et observer la minimisation et la convergence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3JfOQAIlaKmJ",
    "outputId": "f9024f49-af63-43c6-f5c1-507621019082"
   },
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "plt.plot(history_total_loss)\n",
    "plt.plot(history_style_loss)\n",
    "plt.plot(history_content_loss)\n",
    "plt.legend(['total_loss', 'style_loss', 'content_loss'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWVB3anJMY2v"
   },
   "source": [
    "## 8. Perte de variation totale\n",
    "\n",
    "Un inconvénient de cette implémentation de base est qu'elle produit beaucoup d'artefacts liés aux hautes fréquences. Réduisez-les en utilisant un terme de régularisation explicite sur les composantes hautes fréquences de l'image. En transfert de style, ceci est souvent appelé la **perte de variation totale**.\n",
    "\n",
    "La fonction suivant code un filtre passe-haut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7szUUybCQMB3"
   },
   "outputs": [],
   "source": [
    "def high_pass_x_y(image):\n",
    "  x_var = image[:, :, 1:, :] - image[:, :, :-1, :]\n",
    "  y_var = image[:, 1:, :, :] - image[:, :-1, :, :]\n",
    "\n",
    "  return x_var, y_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHH7Wiy8aKmL"
   },
   "source": [
    "Ce filtre peut être testé ainsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Atc2oL29PXu_",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "outputId": "8b298aef-dab8-4cff-aa5f-e7ffe1724a4c"
   },
   "outputs": [],
   "source": [
    "x_deltas, y_deltas = high_pass_x_y(content_image)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "imshow(clip_0_1(2*y_deltas+0.5), \"Horizontal Deltas: Original\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "imshow(clip_0_1(2*x_deltas+0.5), \"Vertical Deltas: Original\")\n",
    "\n",
    "x_deltas, y_deltas = high_pass_x_y(image)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "imshow(clip_0_1(2*y_deltas+0.5), \"Horizontal Deltas: Styled\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "imshow(clip_0_1(2*x_deltas+0.5), \"Vertical Deltas: Styled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqHElVgBkgkz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cela montre comment les composantes de haute fréquence ont augmenté."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv5bKlSDnPP7"
   },
   "source": [
    "La **fonction de coût de variation totale** est une sorte de fonction de régularisation sur ces composantes hautes fréquences. Elle peut être codée ainsi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mP-92lXMIYPn"
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(image):\n",
    "  x_deltas, y_deltas = high_pass_x_y(image)\n",
    "  return tf.reduce_sum(tf.abs(x_deltas)) + tf.reduce_sum(tf.abs(y_deltas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4OYBUX2KQ25",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3dc6a4ce-8a7c-4f7b-d922-5de457b736da"
   },
   "outputs": [],
   "source": [
    "total_variation_loss(image).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu2hJ8zOKMc1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "En fait, il n'est pas nécessaire de l'implémenter vous-même, TensorFlow inclut une implémentation standard qui donne le même résultat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQjWW04NKLfJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d45763ba-beea-4697-ac12-0ef3ab10d370"
   },
   "outputs": [],
   "source": [
    "tf.image.total_variation(image).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTessd-DCdcC"
   },
   "source": [
    "Nous allons modifier le code pour intégrer ce nouveau terme. **La contribution de ce nouveau terme doit d'abord être fixée:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGeRLD4GoAd4"
   },
   "outputs": [],
   "source": [
    "total_variation_weight=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kG1-T4kJsoAv"
   },
   "source": [
    "**Question: Modifiez la fonction `train_step` pour intégrer ce nouveau terme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzmfcyyYUyWq"
   },
   "outputs": [],
   "source": [
    "history_total_loss = []\n",
    "history_style_loss = []\n",
    "history_content_loss = []\n",
    "history_total_variation_loss = []\n",
    "\n",
    "#@tf.function()\n",
    "def train_step(image):\n",
    "\n",
    "    # forward pass avec enregistrement de tous les activations\n",
    "    with tf.GradientTape() as tape:\n",
    "        # extraction des features pour l'image à synthétiser\n",
    "        style_outputs = style_extractor(image)\n",
    "        content_outputs = content_extractor(image)\n",
    "\n",
    "        # calcul de la fonction de coût\n",
    "        loss, style_loss, content_loss = style_content_loss(style_outputs,content_outputs)\n",
    "\n",
    "        # avec total variation\n",
    "# ----------- Your code here --------------------->\n",
    "#         total_variation_loss = ...\n",
    "#         loss += ...\n",
    "\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "\n",
    "    # calcul des gradients par rétropropagation\n",
    "    grad = tape.gradient(loss, image)\n",
    "\n",
    "    # application des gradients aux paramètres (ici l'image)\n",
    "    opt_fcn.apply_gradients([(grad, image)])\n",
    "\n",
    "    # mise à jour\n",
    "    image.assign(clip_0_1(image))\n",
    "\n",
    "    history_total_loss.append(loss)\n",
    "    history_style_loss.append(style_loss)\n",
    "    history_content_loss.append(content_loss)\n",
    "    history_total_variation_loss.append(total_variation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcLWBQChsutQ"
   },
   "source": [
    "**Réinitialisez ensuite la variable d'optimisation :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-dPRr8BqexB"
   },
   "outputs": [],
   "source": [
    "image = tf.Variable(content_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEflRstmtGBu"
   },
   "source": [
    "**Et relancez l'optimisation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3Cc3bLtoOWy",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "outputId": "5ce8abee-8c25-4341-a475-a3ed1341599e"
   },
   "outputs": [],
   "source": [
    "# démarrage du chrono\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# paramètres\n",
    "epochs = 10\n",
    "steps_per_epoch = 100\n",
    "\n",
    "# boucle sur les épochs\n",
    "step = 0\n",
    "for n in range(epochs):\n",
    "    for m in range(steps_per_epoch):\n",
    "        step += 1\n",
    "\n",
    "        # un pas de descente de gradient\n",
    "        train_step(image)\n",
    "\n",
    "        # display\n",
    "        print(\".\", end='', flush=True)\n",
    "\n",
    "    # display\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(tensor_to_image(image))\n",
    "    print(\"Train step: {}\".format(step))\n",
    "\n",
    "# arret du chrono et affichage\n",
    "end = time.time()\n",
    "print(\"Total time: {:.1f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZJ77dJ3AaKmP",
    "outputId": "3b6d5a56-2597-47fc-e33a-0d7e1438e419"
   },
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "plt.plot(history_total_loss)\n",
    "plt.plot(history_style_loss)\n",
    "plt.plot(history_content_loss)\n",
    "plt.plot(history_total_variation_loss)\n",
    "plt.legend(['total_loss', 'style_loss', 'content_loss', 'history_total_variation_loss'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKox7K46tKxy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Enfin, si vous le souhaitez, sauvez l'image générée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSH6OpyyQn7w",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "outputId": "9c556c09-e8a7-4b79-f61d-6937b69e4549"
   },
   "outputs": [],
   "source": [
    "# sauve sur le disque ou dans le drive\n",
    "file_name = './results/'+'stylized-image.png'\n",
    "tensor_to_image(image).save(file_name)\n",
    "\n",
    "# permet de télécharger du drive\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "      from google.colab import files\n",
    "    except ImportError:\n",
    "      pass\n",
    "    else:\n",
    "      files.download(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3Ecg8j6oaKmQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
