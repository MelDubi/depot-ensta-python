{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Machine Learning Programming Exercise 7</center>\n",
    "# <center> **Partie 1: Exploration de la librairie Tensorflow 2.x** </center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| <font size=6,font color='red'>Monôme / binôme</font> | <font size=6,font color='red'>Nom</font> | <font size=6,font color='red'>Prénom</font> |\n",
    "|:-------------: |:----------- |:------ |\n",
    "| monôme/binôme 1 | <span style=\"color:red\">Remplacer ici</span> | <span style=\"color:red\">et ici</span> |\n",
    "| binôme 2 | <span style=\"color:red\">Remplacer ici</span> | <span style=\"color:red\">et ici</span> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UaFmaExs_9q"
   },
   "source": [
    "Jusqu'à présent, vous avez toujours utilisé numpy pour construire des petits réseaux de neurones. Nous allons maintenant découvrir un framework plus adapté pour l'apprentissage et l'utilisation de modèles de réseaux de neurones possédants un grand nombre de paramètres. Ce type de modèles fait usage de nombreux calculs qui peuvent être parallélisés. Un framework de machine learning (tel que TensorFlow, pyTorch, etc.) faisant usage de calculs sur GPUs peut alors accélérer considérablement le développement de votre algorithme d'apprentissage. Ces frameworks permettent également (comme scikit-learn) la création rapide et simplifiée de réseaux de neurones.\n",
    "Tous ces frameworks sont accompagnés d'une abondante documentation, que vous pouvoir lire librement. \n",
    "\n",
    "Dans ce TP, vous apprendrez avec TensorFlow 2.0 à initialiser les tenseurs et calculer mais aussi à élaborer, apprendre, analyser et évaluer un modèle de réseau de neurones.\n",
    "\n",
    "Vous devez:\n",
    "- compléter le code aux endroits indiqués;\n",
    "- élaborer, apprendre, analyser et évaluer avec tensorflow, un réseau de neurones sur la base d'images de fonds marins (rencontrés dans un TP précédent)\n",
    "\n",
    "Ce tutoriel est largement basé sur ces sources: \n",
    " - Francois Chollet's github (Tensorflow_2_0_+_Keras_Crash_Course.ipynb)\n",
    " - Boscher's github (v02_Tensorflow_2_0_+_Keras_Crash_Course.ipynb)\n",
    " - MIT course's github (Part1_TensorFlow.ipynb)\n",
    " - Magnus Erik Hvass Pedersen's github (https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/01_Simple_Linear_Model.ipynb)\n",
    "\n",
    "Le framework TensorFlow tire son nom de sa gestion des flux (flow = node = opération mathématique) de tenseurs, qui sont des structures de données que l'on peut considérer comme des tableaux multidimensionnels. Les tenseurs sont représentés par des tableaux à $n$ dimensions de types de données de base tels qu'une chaîne ou un entier. Ils permettent de généraliser les vecteurs et les matrices à des dimensions plus élevées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjC_taT2s_9w"
   },
   "source": [
    "## 1 - Imports\n",
    "\n",
    "Pour pouvoir commencer, vous importerez les librairies suivantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Colab or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "import sys,os,glob\n",
    "\n",
    "# Colab preamble\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "\n",
    "  # mount google drive directories\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive', force_remount=True) \n",
    "\n",
    "\n",
    "  # ----------- Your code here --------------------->\n",
    "  # replace the ipynb_name (below) with the name of your jupyter notebook file\n",
    "\n",
    "  ipynb_name = 'XXXXXXX.ipynb'\n",
    "\n",
    "  # ------------------------------------------------>\n",
    "\n",
    "  ipynb_name = glob.glob(os.getcwd() + '/**/' + ipynb_name, recursive = True)\n",
    "  code_folder = os.path.dirname(ipynb_name[0])\n",
    "\n",
    "  # change to the right folder\n",
    "  %cd \"$code_folder\"\n",
    "  !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXFHKC1Fs_9y",
    "outputId": "5f4296a0-d3ec-4791-f7ec-77af919d6519"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWKq9zLds_90"
   },
   "source": [
    "## 2 - Déclarer des tenseurs constants\n",
    "\n",
    "Vous vous reporterez à [l'adresse suivante](https://www.tensorflow.org/guide/tensor) pour plus de détails.\n",
    "\n",
    "\n",
    "### 2.1 - Tenseurs 0-d\n",
    "Examinons d'abord les tenseurs 0-d, dont un scalaire, une chaîne de caractères sont des exemples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zS3GQuoas_92",
    "outputId": "efb5a1b9-a361-48fe-89e5-19f810c08cf9"
   },
   "outputs": [],
   "source": [
    "sport = tf.constant(\"Tennis\", tf.string)\n",
    "number = tf.constant(1.41421356237, tf.float64)\n",
    "print(sport)\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TDfaZ-Ms_92"
   },
   "source": [
    "### 2.2 - Tenseurs constants 1-d\n",
    "Une manière classique de créer des tenseurs constants est d'utiliser `tf.ones` ou `tf.zeros` (comme en numpy `np.ones` et `np.zeros`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-N9lbTl_s_93",
    "outputId": "2be7c1cf-2a52-4825-bba2-a5b2b4ea87a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tf.ones(shape=(2, 1)))\n",
    "print(tf.zeros(shape=(2, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFenZ1NVs_94"
   },
   "source": [
    "Les listes peuvent être utilisées pour créer des tenseurs 1d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IUygNMks_96",
    "outputId": "763eaea0-69e8-4e6e-b583-6ed16534c580"
   },
   "outputs": [],
   "source": [
    "sports = tf.constant([\"Tennis\", \"Basketball\"], tf.string)\n",
    "numbers = tf.constant([3.141592, 1.414213, 2.71821], tf.float64)\n",
    "print(sports)\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM91QZu4s_98"
   },
   "source": [
    "### 2.3 - Tenseurs n-d\n",
    "Ensuite, nous pouvons créer des tenseurs 2-d (c'est-à-dire des matrices) et des tenseurs de rang supérieur. Dans les TP suivants de traitement d'images, nous utiliserons des tenseurs 4-d. Ces dimensions correspondent au nombre d'images d'exemple dans notre base de données, à la hauteur et à la largeur de l'image, ainsi qu'au nombre de canaux de couleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZ_PXAmws_99",
    "outputId": "4736962d-7112-4d36-9450-39efb1899d0f"
   },
   "outputs": [],
   "source": [
    "### Defining higher-order Tensors ###\n",
    "\n",
    "# ----------- Your code here --------------------->\n",
    "# Define a 2-d Tensor constant 2 x 2, with [5,2] sur la première ligne et [1,3] sur la seconde.\n",
    "\n",
    "matrix =  ... # TODO\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "print(matrix)\n",
    "\n",
    "# les méthodes suivantes seront expliquées plus tard\n",
    "assert isinstance(matrix, tf.Tensor), \"matrix must be a tf Tensor object\"\n",
    "assert tf.rank(matrix).numpy() == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJLpXcZms_99",
    "outputId": "43ecd3ad-b91c-4677-89e9-767a589e5451"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "# Define a 4-d Tensor.\n",
    "# Use tf.zeros to initialize a 4-d Tensor of zeros with size 10 x 256 x 256 x 3. \n",
    "#   You can think of this as 10 images where each image is RGB 256 x 256.\n",
    "\n",
    "images = tf.zeros(shape=(10,256,256,3))# TODO\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "\n",
    "print(images)\n",
    "\n",
    "# les méthodes suivantes seront expliquées plus tard\n",
    "assert isinstance(images, tf.Tensor), \"matrix must be a tf Tensor object\"\n",
    "assert tf.rank(images).numpy() == 4, \"matrix must be of rank 4\"\n",
    "assert tf.shape(images).numpy().tolist() == [10, 256, 256, 3], \"matrix is incorrect shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_2gn5F_s_9-"
   },
   "source": [
    "### 2.4 - Générer des nombres aléatoires\n",
    "- créer un tenseur constant contenant des réels générés aléatoirement par une **distribution gaussienne** dans : `tf.random.normal`\n",
    "- créer un tenseur constant contenant des entiers générés aléatoirement par une **distribution uniforme** dans `tf.random.uniform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLZMWBOKs_9_",
    "outputId": "eed16e40-011b-4c07-bf3b-7158ab2430a2"
   },
   "outputs": [],
   "source": [
    "tf.random.normal(shape=(2, 2), mean=0., stddev=1., seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1geEbSZus_9_",
    "outputId": "03370efa-d781-49ac-9bbc-7356459442bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.uniform(shape=(2, 2), minval=0, maxval=10, dtype='int32', seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcAycze0s_-A"
   },
   "source": [
    "### 3 - Trouver/changer les caractéristiques des tenseurs (méthodes de tenseurs)\n",
    "\n",
    "#### 3.1 - Convertir de tensorflow vers numpy (et inversement)\n",
    "\n",
    "Vous pouvez faire la conversion par un appel à la fonction `.numpy()` and faire la conversion inverse avec  `tf.convert_to_tensor()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HvvguX-Ms_-A",
    "outputId": "b76720e2-5bfc-4cd2-8dad-82fcdc069529"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "# choose a previously defined tensor.\n",
    "T = ... # TO DO \n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "print(T)\n",
    "\n",
    "print('vers numpy:')\n",
    "T_np=T.numpy()\n",
    "print(T_np)\n",
    "\n",
    "print('retour à tf:')\n",
    "tf_T = tf.convert_to_tensor(T_np)\n",
    "print(tf_T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_zMzmTis_-C"
   },
   "source": [
    "#### 3.2 - Gérer le data type: connaitre, convertir\n",
    "\n",
    "- Choisissez un des tenseurs définis précédemment ou initialiser en un nouveau;\n",
    "- La commande `dtype` permet de s'informer sur son data type (Plus de détails à l'[adresse suivante](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType));\n",
    "- Réalisez les conversions de type avec `tf.cast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ji3xT3ms_-C",
    "outputId": "a38d9e58-ef63-4dc3-8314-3ab72d4bf9d0"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "# choose a previously defined tensor.\n",
    "\n",
    "T = ... # TO DO \n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "print(\"`T` is a Tensor with data type: {}\".format(T.dtype))\n",
    "\n",
    "# cast to float\n",
    "T_f32 = tf.cast(T, dtype=tf.float32)\n",
    "print(T_f32)\n",
    "\n",
    "print(tf.cast(T, dtype=tf.int64))\n",
    "\n",
    "#print(tf.cast(T, dtype=tf.string))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uoafnf4s_-C"
   },
   "source": [
    "#### 3.3 - Connaitre le nombre de dimensions (rang) et la taille de chaque dimension\n",
    "- La ```shape``` d'un tenseur définit son nombre de dimensions et la taille de chaque dimension. \n",
    "- Le ```rank``` d'un tenseur fournit le nombre de dimensions ($n$-dimensions) -- vous pouvez aussi considérer cela comme l'ordre ou le degré du tenseur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klkyR4oqs_-D",
    "outputId": "5745da0f-6952-43b1-dc7f-9dba1991db9a"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "# choose a previously defined tensor.\n",
    "\n",
    "T = ... # TO DO \n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "print(\"`T` is a {}-d Tensor with shape: {}\".format(tf.rank(T).numpy(), tf.shape(T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uu-hZXf6s_-D"
   },
   "source": [
    "#### 3.4 - Sur quel device est stocké le tenseur?\n",
    "La commande `.device` permet de connaitre si le tenseur est stocké dans la mémoire du GPU ou du CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTXAWR3ys_-D",
    "outputId": "6f92000f-79ae-40b6-d799-c8015ac0f0ce"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "# choose a previously defined tensor.'''\n",
    "\n",
    "T = ... # TO DO \n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "print(\"`T` is a {} Tensor\".format(T.device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6lfCKYYs_-E"
   },
   "source": [
    "#### 3.5 - Indexer les tenseurs pour accèder aux sous-tenseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-FGEe5Ss_-E"
   },
   "source": [
    "Comme dans numpy, vous pouvez utiliser le découpage pour accéder aux sous-tenseurs d'un tenseur de rang supérieur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frxOrp8Es_-F",
    "outputId": "e9d367d9-db98-477c-a451-f0e30cfb85af"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "# choose a previously defined tensor.\n",
    "\n",
    "T = ... # TO DO \n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "assert isinstance(T, tf.Tensor), \"T must be a tf Tensor object\"\n",
    "assert tf.rank(T).numpy() > 0, \"T must be of rank greater to 0\"\n",
    "\n",
    "\n",
    "row_vector = T[1]\n",
    "column_vector = T[:,1]\n",
    "scalar = T[1, 1]\n",
    "\n",
    "print(\"`row_vector`: {}\".format(row_vector.numpy()))\n",
    "print(\"`column_vector`: {}\".format(column_vector.numpy()))\n",
    "print(\"`scalar`: {}\".format(scalar.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HJ0pZrps_-F"
   },
   "source": [
    "## 4 - Tenseurs variables\n",
    "\n",
    "Les tenseurs [Variables](https://www.tensorflow.org/guide/variable) sont des cas particuliers des tenseurs permettant de stocker en mémoire des états variables (les valeurs des variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tg3xcI8vs_-F",
    "outputId": "cb72e6e2-124e-476c-9662-003ccbb0264f"
   },
   "outputs": [],
   "source": [
    "initial_value = tf.random.normal(shape=(2, 2))\n",
    "a = tf.Variable(initial_value)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_U1J_lVs_-G"
   },
   "source": [
    "Pour changer la valeurs d'une variable, il faut utiliser les méthodes `.assign(value)`, ou `.assign_add(increment)` ou `.assign_sub(decrement)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5HL2VGNs_-G"
   },
   "outputs": [],
   "source": [
    "new_value = tf.random.normal(shape=(2, 2))\n",
    "a.assign(new_value)\n",
    "# check\n",
    "for i in range(2):\n",
    "  for j in range(2):\n",
    "    assert a[i, j] == new_value[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qg24v155s_-G"
   },
   "outputs": [],
   "source": [
    "added_value = tf.random.normal(shape=(2, 2))\n",
    "a.assign_add(added_value)\n",
    "# check\n",
    "for i in range(2):\n",
    "  for j in range(2):\n",
    "    assert a[i, j] == new_value[i, j] + added_value[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zChQcUJBs_-G"
   },
   "source": [
    "## 5 - Calculer avec les tenseurs \n",
    "\n",
    "### 5.1 Tensorflow définit des graphes pour calculer\n",
    "\n",
    "Une façon pratique d'envisager et de visualiser les calculs dans TensorFlow est de les effectuer sous forme de graphiques. Nous pouvons définir ce graphique en termes de tenseurs, qui contiennent des données, et les opérations mathématiques qui agissent sur ces tenseurs dans un certain ordre. Prenons un exemple simple, et définissons ce calcul à l'aide de TensorFlow :\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1rns_AJ6k_Xdq1RBGTK3lcfUG6qQdU3tK\" style=\"width:600px;height:150px ;\">\n",
    "\n",
    "figure tiré de MIT Deep learning course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gC4J2Dps_-H",
    "outputId": "804ac112-80dd-4834-ddc4-ba6a9789c4e6"
   },
   "outputs": [],
   "source": [
    "# Create the nodes in the graph, and initialize values\n",
    "a = tf.constant(15)\n",
    "b = tf.constant(61)\n",
    "\n",
    "# Add them!\n",
    "c1 = tf.add(a,b)\n",
    "c2 = a + b # TensorFlow overrides the \"+\" operation so that it is able to act on Tensors\n",
    "print(c1)\n",
    "print(c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIE7y5Vjs_-H"
   },
   "source": [
    "Pour obtenit le tenseur de valeur 76, un graphe de calculs composé d'opérations TensorFlow a été créé et exécuté.\n",
    "\n",
    "Considérons maintenant un exemple un peu plus compliqué :\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=181ouV6fjRQ-Ejg26g8HjceUY4PGr6eR2\" style=\"width:400px;height:200px ;\">\n",
    "\n",
    "Ici, nous considérons deux entrées, `a`, `b`, et calculons une sortie `e`. Chaque noeud du graphique représente une opération qui prend une entrée, effectue un calcul et transmet sa sortie à un autre noeud.\n",
    "\n",
    "Définissons une fonction simple dans TensorFlow pour construire cette fonction de calcul :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ClQShlcs_-I"
   },
   "outputs": [],
   "source": [
    "### Defining Tensor computations ###\n",
    "\n",
    "# Construct a simple computation function\n",
    "def func(a,b):\n",
    "\n",
    "    # ----------- Your code here --------------------->\n",
    "    # Define the operation for c, d, e (use tf.math.add, tf.math.subtract, tf.math.multiply).\n",
    "    \n",
    "    c = ...\n",
    "    d = ...\n",
    "    e = ...\n",
    "\n",
    "    # ------------------------------------------------>\n",
    "\n",
    "    \n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCOI-Qkfs_-I"
   },
   "source": [
    "Exécutons cette fonction par le biais d'un graphe en assignant des valeurs aux variables `a,b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTtxDzwks_-I",
    "outputId": "8745aa13-a29d-4c58-e482-9573c512f2b7"
   },
   "outputs": [],
   "source": [
    "# Consider example values for a,b\n",
    "a, b = 1.5, 2.5\n",
    "# Execute the computation\n",
    "e_out = func(a,b)\n",
    "print(e_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-02ftA5s_-I"
   },
   "source": [
    "Autre exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmfLZms6s_-J"
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal(shape=(2, 2))\n",
    "b = tf.random.normal(shape=(2, 2))\n",
    "\n",
    "c = a + b\n",
    "d = tf.square(c)\n",
    "e = tf.exp(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6fEX9VLs_-J"
   },
   "source": [
    "### 5.2 - Fonction linéaire (combinaison linéaire)\n",
    "\n",
    "Calculez l'équation suivante : $h_{W,b}(X) = WX + b$, où $W$ et $X$ sont des matrices aléatoires et $b$ est un vecteur aléatoire. \n",
    "\n",
    "- $X$ et $b$ sont tirés d'une distribution normale aléatoire. \n",
    "- $W$ est de dimension (4, 3), $X$ est (3,1) et $b$ est (4,1). \n",
    "\n",
    "Les fonctions suivantes peuvent vous être utiles : \n",
    "- tf.matmul(..., ...) pour effectuer une multiplication matricielle\n",
    "- tf.add(..., ...) pour faire une addition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHG5OLqLs_-J",
    "outputId": "0dde5711-4435-460a-b613-a3ab3ddc894e"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_function\n",
    "\n",
    "def linear_function():\n",
    "    \"\"\"\n",
    "    Implements a linear function: \n",
    "            Initializes W to be a random tensor of shape (4,3)\n",
    "            Initializes X to be a random tensor of shape (3,1)\n",
    "            Initializes b to be a random tensor of shape (4,1)\n",
    "    Returns: \n",
    "    result -- runs the session for Y = WX + b \n",
    "    \"\"\"\n",
    "    \n",
    "    # mis ici pour contrôler le résultat: Expected output\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "    # ----------- Your code here --------------------->\n",
    "    # START CODE HERE (4 lines of code)\n",
    "    # pour controler le résultat rajouter seed=SEED pour chaque génération aléatoire'''\n",
    "    \n",
    "    X = ...\n",
    "    W = ...\n",
    "    b = ...\n",
    "    H = ...\n",
    "\n",
    "    # ------------------------------------------------>\n",
    "\n",
    "        \n",
    "    return H\n",
    "\n",
    "print( \"result = \" + str(linear_function()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bYdvy3Ys_-K"
   },
   "source": [
    "*** Expected Output ***: \n",
    "\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "**result**\n",
    "</td>\n",
    "<td>\n",
    "[[-0.9966546 ]\n",
    " [-2.6214728 ]\n",
    " [ 3.096904  ]\n",
    " [ 0.02088326]]\n",
    "</td>\n",
    "</tr> \n",
    "\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q645NGePs_-L"
   },
   "source": [
    "### 5.3 - Calculer avec la fonction sigmoïde \n",
    "\n",
    "Vous venez de prorammer une fonction linéaire. Tensorflow offre une variété de fonctions de réseaux de neurones couramment utilisées comme `tf.sigmoid` et `tf.softmax`. Pour cet exercice, nous allons calculer la fonction sigmoïde d'une entrée. \n",
    "\n",
    "Implémentez la fonction sigmoïde ci-dessous. Vous devez utiliser ce qui suit : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55boxFmJs_-L"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "    \n",
    "    Arguments:\n",
    "    z -- input value, scalar or vector\n",
    "    \n",
    "    Returns: \n",
    "    results -- the sigmoid of z\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------- Your code here --------------------->\n",
    "    # Use the tensorflow sigmoid function\n",
    "\n",
    "    result = ...\n",
    "    \n",
    "    # ------------------------------------------------>\n",
    "    \n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCV4eY15s_-L",
    "outputId": "2c42a314-77c4-4136-b2bd-2274d9a285d1"
   },
   "outputs": [],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0.)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-o_Gj67Ks_-L"
   },
   "source": [
    "*** Expected Output ***: \n",
    "\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "**sigmoid(0)**\n",
    "</td>\n",
    "<td>\n",
    "0.5\n",
    "</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td>\n",
    "**sigmoid(12)**\n",
    "</td>\n",
    "<td>\n",
    "0.999994\n",
    "</td>\n",
    "</tr> \n",
    "\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZOUSYCUs_-L"
   },
   "source": [
    "### 5.4 Calcul de la fonction de coût \n",
    "\n",
    "#### 5.4.1 Calcul de fonction de cout de régression \n",
    "\n",
    "Calculez avec Tensorflow la fonction suivante:\n",
    "$$loss = \\mathcal{L}(\\hat{y}, y) = (\\hat y^{(i)} - y^{(i)})^2 \\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ti9LKr7Os_-L",
    "outputId": "0bebc448-e005-4a36-edc8-648dac747276"
   },
   "outputs": [],
   "source": [
    "y_hat = tf.constant(36, name='y_hat')            # Define y_hat constant. Set to 36.\n",
    "y = tf.constant(39, name='y')                    # Define y. Set to 39\n",
    "\n",
    "# ----------- Your code here --------------------->\n",
    "# Define the operation for loss.\n",
    "\n",
    "loss = ... # Create a variable for the loss\n",
    "\n",
    "# ------------------------------------------------>\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoNB8mxQs_-L"
   },
   "source": [
    "*** Expected Output ***: \n",
    "\n",
    "<tf.Variable 'loss:0' shape=() dtype=int32, numpy=9>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id1WgspEs_-M"
   },
   "source": [
    "#### 5.4.2 - Calcul de la fonction de coût \"entropie croisée\" de classification\n",
    "\n",
    "Vous pouvez utiliser une fonction intégrée pour calculer le coût de votre réseau de neurones. Ainsi, au lieu de devoir écrire du code pour le calculer en fonction de $h_\\theta^{(i)}$ et de $y^{(i)}$ pour $i\\in\\{1,\\dots,m\\}$:\n",
    "\n",
    "$$ J(\\theta) = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log h_\\theta^{(i)}(x) + (1-y^{(i)})\\log (1-h_\\theta^{(i)}(x) )\\large )\\small\\tag{2}$$, vous pouvez appeler la fonction `tf.nn.sigmoid_cross_entropy_with_logits(logits = ..., labels = ...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzJdcQAms_-M"
   },
   "outputs": [],
   "source": [
    "def cost(logits, labels):\n",
    "    \"\"\"\n",
    "    Computes the cost using the sigmoid cross entropy\n",
    "    \n",
    "    Arguments:\n",
    "    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n",
    "    labels -- vector of labels y (1 or 0) \n",
    "        \n",
    "    Returns:\n",
    "    cost -- the cost \n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------- Your code here --------------------->\n",
    "    # Use the loss function (approx. 1 line)\n",
    "\n",
    "    cost = ...\n",
    "\n",
    "    # ------------------------------------------------>\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F03Ql-4Ns_-N"
   },
   "source": [
    "Pour évaluer la fonction cost, vous devez mettre en entrée logits et labels:\n",
    "- La variable logits sera ici la sortie de la fonction `linear_function()` précédemment définie. \n",
    "- Définissez pour les labels un vecteur constant de 4 valeurs: 0., 0., 1., 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cleP2c11s_-N",
    "outputId": "df478493-d441-4b07-a2ba-bd10b7eff53f"
   },
   "outputs": [],
   "source": [
    "# ----------- Your code here --------------------->\n",
    "# Define logits as the outputs of linear_function and some compatible labels (use tf.transpose if )\n",
    "\n",
    "logits = ...\n",
    "labels = ...\n",
    "\n",
    "# ------------------------------------------------>\n",
    "\n",
    "# losses and loss\n",
    "cost_i = cost(logits, labels)\n",
    "print (\"cost_i = \" + str(cost_i))\n",
    "\n",
    "cost_tot = tf.math.reduce_mean(cost_i)\n",
    "print (\"cost = \" + str(cost_tot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7jFMGjas_-N"
   },
   "source": [
    "*** Expected Output ***: \n",
    "\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "**cost_i**\n",
    "</td>\n",
    "<td>\n",
    "[[0.3141625 ]\n",
    " [0.07017484]\n",
    " [0.04419762]\n",
    " [0.68276006]]\n",
    "</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td>\n",
    "**cost**\n",
    "</td>\n",
    "<td>\n",
    "0.27782375\n",
    "</td>\n",
    "</tr> \n",
    "\n",
    "</table> \n",
    "\n",
    "cost_i = tf.Tensor(\n",
    "[[0.3141625 ]\n",
    " [0.07017484]\n",
    " [0.04419762]\n",
    " [0.68276006]], shape=(4, 1), dtype=float32)\n",
    " \n",
    "cost = tf.Tensor(0.27782375, shape=(), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgA6eYHus_-N"
   },
   "source": [
    "## 5 - Calculer les gradients automatiquement (Automatic differentiation) \n",
    "\n",
    "Le calcul des gradients ([Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) ) est une des plus importantes parties de Tensorflow car elle permet l'apprentissage des réseaux de neurones par [rétropropagation](https://en.wikipedia.org/wiki/Backpropagation).\n",
    "On utilisera le gestionnaire de contexte [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape?version=stable) pour calculer les gradients. \n",
    "\n",
    "L'exemple suivant montre comment calculer les gradients pour la fonction $ y = x^2$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6GTYq7Ss_-O"
   },
   "outputs": [],
   "source": [
    "### Gradient computation with GradientTape ###\n",
    "\n",
    "# y = x^2\n",
    "# Example: x = 3.0\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "# Initiate the gradient tape\n",
    "with tf.GradientTape() as tape:\n",
    "  # Define the function\n",
    "  y = x * x\n",
    "    \n",
    "# Access the gradient -- derivative of y with respect to x\n",
    "dy_dx = tape.gradient(y, x)\n",
    "\n",
    "assert dy_dx.numpy() == 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQt083qLs_-P"
   },
   "source": [
    "A partir de l'exemple précédent utilisant `GradientTape`, nous allons examiner un exemple où nous utilisons la différenciation automatique et la SGD pour trouver le minimum de $J=(x-x_f)^2$. Ici, $x_f$ est une variable pour une valeur souhaitée que nous essayons d'estimer ; $J$ représente un coût que nous essayons de minimiser. \n",
    "\n",
    "Bien que nous puissions clairement résoudre ce problème de manière analytique ($x_{min}=x_f$), on va le faire avec `GradientTape`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "EN7gxVOus_-P",
    "outputId": "f75065c0-999e-4132-a0ab-a54d8cb2685c"
   },
   "outputs": [],
   "source": [
    "### Function minimization with automatic differentiation and SGD ###\n",
    "\n",
    "# Initialize a random value for our initial x\n",
    "x = tf.Variable([tf.random.normal([1])])\n",
    "print(\"Initializing x={}\".format(x.numpy()))\n",
    "\n",
    "learning_rate = 1e-2 # learning rate for SGD\n",
    "history = []\n",
    "# Define the target value\n",
    "x_f = 4\n",
    "\n",
    "# We will run SGD for a number of iterations. At each iteration, we compute the loss, \n",
    "#   compute the derivative of the loss with respect to x, and perform the SGD update.\n",
    "for i in range(500):\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "      \n",
    "    # ----------- Your code here --------------------->\n",
    "    # define the loss as described above \n",
    "      \n",
    "    loss = ...\n",
    "\n",
    "    # ------------------------------------------------>\n",
    "      \n",
    "  # loss minimization using gradient tape\n",
    "  grad = tape.gradient(loss, x) # compute the derivative of the loss with respect to x\n",
    "  new_x = x - learning_rate*grad # sgd update\n",
    "  x.assign(new_x) # update the value of x\n",
    "  history.append(x.numpy()[0])\n",
    "\n",
    "# Plot the evolution of x as we optimize towards x_f!\n",
    "plt.plot(history)\n",
    "plt.plot([0, 500],[x_f,x_f])\n",
    "plt.legend(('Predicted', 'True'))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('x value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54yJEUCUs_-P"
   },
   "source": [
    "Notez qu'on peut calculer les dérivées d'ordre supérieur par imbrication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74DVvF-ss_-Q",
    "outputId": "ab6381a7-cea0-435f-db4d-8051eabfb874"
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal(shape=(2, 2))\n",
    "b = tf.random.normal(shape=(2, 2))\n",
    "a = tf.Variable(a)\n",
    "\n",
    "with tf.GradientTape() as outer_tape:\n",
    "  with tf.GradientTape() as tape:\n",
    "    c = tf.sqrt(tf.square(a) + tf.square(b))\n",
    "    dc_da = tape.gradient(c, a)\n",
    "  d2c_da2 = outer_tape.gradient(dc_da, a)\n",
    "  print(d2c_da2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfXiv5uks_-Q"
   },
   "source": [
    "## 5.6 - Conversion de labels: one-hot-encoding\n",
    "\n",
    "Souvent, en machine learning, vous aurez un vecteur $y$ avec des nombres allant de $0$ à $C$, où $C$ est le nombre de classes. Si $C$ est par exemple 4, alors vous pourriez avoir le vecteur $y$ suivant que vous devrez convertir comme suit :\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1NfPufghD8v2LC6I0kSs76B-5pzxhMObA\" style=\"width:600px;height:150px ;\">\n",
    "\n",
    "\n",
    "On appelle cela un encodage \"one hot\", car dans la représentation finale, un seul élément de chaque colonne est \"hot\" (c'est-à-dire mis à 1). Dans tensorflow, vous pouvez utiliser une ligne de code : \n",
    "\n",
    "- tf.one_hot(labels, class_nb, axis) \n",
    "\n",
    "**Exercice : ** Implémentez la fonction ci-dessous pour prendre un vecteur d'étiquettes et le nombre total de classes $C$, et encoder le en one-hot. Utilisez `tf.one_hot()` pour faire cela. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "namsu6Jhs_-Q"
   },
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, class_nb):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    class_nb -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------- Your code here --------------------->\n",
    "   \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    class_nb = ...\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = ...\n",
    " \n",
    "    # ------------------------------------------------>\n",
    "    \n",
    "    return one_hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3oTXRSns_-R",
    "outputId": "fdbbaa60-c450-4b33-a68b-585be99624a2"
   },
   "outputs": [],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, class_nb = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02P6zzCms_-R"
   },
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **one_hot**\n",
    "        </td>\n",
    "        <td>\n",
    "        [[ 0.  0.  0.  1.  0.  0.]\n",
    " [ 1.  0.  0.  0.  0.  1.]\n",
    " [ 0.  1.  0.  0.  1.  0.]\n",
    " [ 0.  0.  1.  0.  0.  0.]]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
